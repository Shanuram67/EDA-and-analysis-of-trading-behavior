# ============================================================
# CELL 1: Setup, imports, and folder creation
# ============================================================
import os
from pathlib import Path
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.decomposition import PCA
from sklearn.cluster import KMeans
import statsmodels.api as sm
from scipy.stats import zscore

# Paths (Colab runtime)
PROJECT_ROOT = Path.cwd()
CSV_DIR = PROJECT_ROOT / "csv_files"
OUT_DIR = PROJECT_ROOT / "outputs"
CSV_DIR.mkdir(exist_ok=True)
OUT_DIR.mkdir(exist_ok=True)

pd.set_option('display.max_columns', 100)
sns.set(style="whitegrid", palette="Set2")
# ============================================================
# CELL 2: Load data
# ============================================================
traders_path = CSV_DIR / "traders.csv"
sentiment_path = CSV_DIR / "sentiment.csv"

# Load with correct datetime parsing
traders = pd.read_csv(traders_path, parse_dates=['Timestamp'], infer_datetime_format=True)
sentiment = pd.read_csv(sentiment_path, parse_dates=['timestamp', 'date'], infer_datetime_format=True)

print("Traders shape:", traders.shape)
print("Sentiment shape:", sentiment.shape)
traders.head()
# ============================================================
# CELL 3: Normalize column names & feature engineering
# ============================================================
traders.columns = traders.columns.str.strip().str.lower()
sentiment.columns = sentiment.columns.str.strip().str.lower()

# Convert timestamps to date
traders['date'] = pd.to_datetime(traders['timestamp'], unit='ms', errors='coerce').dt.date
sentiment['date'] = pd.to_datetime(sentiment['date'], dayfirst=True, errors='coerce').dt.date

# Ensure numeric columns
traders['execution price'] = pd.to_numeric(traders['execution price'], errors='coerce')
traders['size tokens'] = pd.to_numeric(traders['size tokens'], errors='coerce')
traders['size usd'] = pd.to_numeric(traders['size usd'], errors='coerce')
traders['closed pnl'] = pd.to_numeric(traders['closed pnl'], errors='coerce').fillna(0)
traders['fee'] = pd.to_numeric(traders['fee'], errors='coerce').fillna(0)

# Derived metrics
traders['notional'] = traders['size usd']
traders['gross_amount'] = traders['execution price'] * traders['size tokens']
traders['side_num'] = traders['side'].map({'Buy': 1, 'Sell': -1}).fillna(0)
traders['net_effect'] = traders['side_num'] * traders['size usd']

traders[['account','coin','date','closed pnl','notional','fee']].head()
# ============================================================
# CELL 4: Aggregate trading behavior
# ============================================================

# Per trader per day
daily_trader = traders.groupby(['account', 'date']).agg(
    trades_count=('trade id', 'count'),
    total_volume_usd=('size usd', 'sum'),
    total_notional=('notional', 'sum'),
    gross_pnl=('closed pnl', 'sum'),
    total_fees=('fee', 'sum'),
    avg_execution_price=('execution price', 'mean'),
).reset_index()

# Market-level aggregation per day
daily_market = traders.groupby('date').agg(
    total_trades=('trade id', 'count'),
    total_volume_usd=('size usd', 'sum'),
    total_pnl=('closed pnl', 'sum'),
    avg_execution_price=('execution price', 'mean'),
).reset_index()

print("Daily trader shape:", daily_trader.shape)
print("Daily market shape:", daily_market.shape)
daily_trader.head()
# ============================================================
# CELL 5: Prepare sentiment data
# ============================================================

# sentiment.csv columns: timestamp, value, classification, date
# "value" represents numeric sentiment index (fear vs greed)
sentiment['value'] = pd.to_numeric(sentiment['value'], errors='coerce')

# optional sanity check
print(sentiment['classification'].value_counts())
sentiment[['date','value','classification']].head()
# ============================================================
# CELL 6: Merge daily market data with sentiment
# ============================================================

# Merge using 'date'
daily = pd.merge(daily_market, sentiment[['date','value','classification']], on='date', how='left')

# Sort by date
daily.sort_values('date', inplace=True)
daily.rename(columns={'value':'sentiment_value'}, inplace=True)

print("Merged dataset shape:", daily.shape)
daily.head()
# ============================================================
# CELL 7: Plot total trading volume vs sentiment value
# ============================================================
fig, ax1 = plt.subplots(figsize=(12,5))
ax2 = ax1.twinx()

ax1.plot(daily['date'], daily['total_volume_usd'], color='tab:blue', label='Total Volume (USD)')
ax2.plot(daily['date'], daily['sentiment_value'], color='tab:red', linestyle='--', label='Sentiment Value')

ax1.set_xlabel('Date')
ax1.set_ylabel('Total Volume (USD)', color='tab:blue')
ax2.set_ylabel('Sentiment Value', color='tab:red')

ax1.legend(loc='upper left')
ax2.legend(loc='upper right')
plt.title('Market Volume vs Sentiment Value')
plt.savefig(OUT_DIR / "volume_vs_sentiment.png", bbox_inches='tight')
plt.show()
# ============================================================
# CELL 9: Cluster traders based on performance patterns
# ============================================================

# Create trader-level features
t_features = daily_trader.groupby('account').agg(
    mean_trades=('trades_count','mean'),
    mean_volume_usd=('total_volume_usd','mean'),
    mean_pnl=('gross_pnl','mean'),
    mean_fee=('total_fees','mean'),
).fillna(0)

# Normalize features
X = t_features.apply(zscore).fillna(0)

# Cluster into 3 groups
kmeans = KMeans(n_clusters=3, random_state=42)
t_features['cluster'] = kmeans.fit_predict(X)

t_features.reset_index().to_csv(CSV_DIR / 'trader_clusters.csv', index=False)
print("Trader clusters saved.")
t_features.head()
# ============================================================
# CELL 10: Analyze how clusters behave across sentiment regimes
# ============================================================

# Map clusters back to daily_trader
cluster_map = t_features['cluster'].to_dict()
daily_trader['cluster'] = daily_trader['account'].map(cluster_map)

# Merge with sentiment by date
sent_df = sentiment[['date','value']].rename(columns={'value':'sentiment_value'})
dt = daily_trader.merge(sent_df, on='date', how='left')

# Bin sentiment into fear / neutral / greed
dt['sent_bin'] = pd.qcut(dt['sentiment_value'].fillna(0), q=3, labels=['fear','neutral','greed'])

summary = dt.groupby(['cluster','sent_bin']).agg(
    avg_pnl=('gross_pnl','mean'),
    avg_volume_usd=('total_volume_usd','mean'),
    count_days=('date','nunique')
).reset_index()

summary.to_csv(CSV_DIR/'cluster_sentiment_summary.csv', index=False)
summary

# ============================================================
# CELL 11: Signal test â€” does sharp sentiment increase precede gains?
# ============================================================
daily['sent_diff'] = daily['sentiment_value'].diff()
threshold = daily['sent_diff'].std()

signal_days = daily[daily['sent_diff'] > threshold]
next_day_pnls = []

for idx in signal_days.index:
    nxt_idx = idx + 1
    if nxt_idx < len(daily):
        next_day_pnls.append(daily.iloc[nxt_idx]['total_pnl'])

if len(next_day_pnls) > 0:
    print(f"Avg next-day PnL after large sentiment increase: {np.mean(next_day_pnls):.2f}")
else:
    print("No significant sentiment jumps detected.")
# ============================================================
# CELL 12: Save outputs
# ============================================================
daily.to_csv(CSV_DIR / 'daily_market_sentiment_agg.csv', index=False)
print("Saved daily aggregates and cluster summaries to csv_files/")

for f in OUT_DIR.iterdir():
    print("Output saved:", f.name)
